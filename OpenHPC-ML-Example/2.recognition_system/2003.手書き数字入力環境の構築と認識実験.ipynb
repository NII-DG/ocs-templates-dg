{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "db53a638-a9ff-11ec-b2f2-02420a010024-6-8df7-7404-8973-2adb-babd-af24",
     "next": "db53a7a0-a9ff-11ec-b2f2-02420a010024-6-aaeb-b8cd-6741-5c1e-d5b0-a0d7",
     "previous": null
    }
   },
   "source": [
    "# フリーハンド入力した手書き数字の認識\n",
    "\n",
    "---\n",
    "\n",
    "一般に機械学習アプリケーションは、ユーザとのインターラクションのためのフロントエンドと認識システムとを一体化する構成が多いと思われます。しかし、本テンプレートででは簡単化のために Jupyter Notebook をフロントエンド環境として使用し、認識は先に構築した認識システムを使用します。\n",
    "\n",
    "本Notebookでは、フロントエンドで入力した手書き数字をイメージファイルとして認識システムに転送、認識システムで認識し、結果をフロントエンドに戻します。\n",
    "\n",
    "![構成](images/230.frontend.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "db53a7a0-a9ff-11ec-b2f2-02420a010024-6-aaeb-b8cd-6741-5c1e-d5b0-a0d7",
     "next": "db53a7a0-a9ff-11ec-b2f2-02420a010024-7-aaeb-b8cd-6741-7574-b91c-69ba-02dc",
     "previous": "db53a638-a9ff-11ec-b2f2-02420a010024-6-8df7-7404-8973-2adb-babd-af24"
    }
   },
   "source": [
    "## 認識システム設定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "db53a7a0-a9ff-11ec-b2f2-02420a010024-7-aaeb-b8cd-6741-7574-b91c-69ba-02dc",
     "next": "db53a8ae-a9ff-11ec-b2f2-02420a010024-6-5379-4e3b-e9b7-30c2-2fec-a70c",
     "previous": "db53a7a0-a9ff-11ec-b2f2-02420a010024-6-aaeb-b8cd-6741-5c1e-d5b0-a0d7"
    }
   },
   "source": [
    "使用する認識システムの `UnitGroup` 名を指定します。なお、内部的には UnitGroup 名のついたファイル名をアクセスするだけで、VCP へはアクセスしません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lc_cell_meme": {
     "current": "db53a8ae-a9ff-11ec-b2f2-02420a010024-6-5379-4e3b-e9b7-30c2-2fec-a70c",
     "next": "db53ad40-a9ff-11ec-b2f2-02420a010024-6-d4fb-afcb-67a2-5b71-4646-e9e9",
     "previous": "db53a7a0-a9ff-11ec-b2f2-02420a010024-7-aaeb-b8cd-6741-7574-b91c-69ba-02dc"
    },
    "lc_wrapper": {}
   },
   "outputs": [],
   "source": [
    "rs_ugroup_name = 'TfCpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "db53ad40-a9ff-11ec-b2f2-02420a010024-6-d4fb-afcb-67a2-5b71-4646-e9e9",
     "next": "1fa79326-d0e3-11ec-b26a-0242ac110002-3-04bc-c621-a9fb",
     "previous": "db53a8ae-a9ff-11ec-b2f2-02420a010024-6-5379-4e3b-e9b7-30c2-2fec-a70c"
    }
   },
   "source": [
    "## 準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "1fa79326-d0e3-11ec-b26a-0242ac110002-3-04bc-c621-a9fb",
     "next": "672f5f8a-d0e3-11ec-b26a-0242ac110002-3-a463-3dba-59f6",
     "previous": "db53ad40-a9ff-11ec-b2f2-02420a010024-6-d4fb-afcb-67a2-5b71-4646-e9e9"
    }
   },
   "source": [
    "### 認識、学習システムのパラメータ読み出し"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "672f5f8a-d0e3-11ec-b26a-0242ac110002-3-a463-3dba-59f6",
     "next": "672f6174-d0e3-11ec-b26a-0242ac110002-3-7c89-256b-e677",
     "previous": "1fa79326-d0e3-11ec-b26a-0242ac110002-3-04bc-c621-a9fb"
    }
   },
   "source": [
    "認識システムのパラメータを読み出します。学習システムを構築した場合(trainingたsystem = True)学習システムのパラメータも読み出します。次の場合エラーとなります。\n",
    "* training_system = True かつ学習システム構築Notebookの作業フォルダ({ohpc_WORK_DIR})が存在しない\n",
    "* training_system = True かつ学習システムの UnitGroup 名({ts_ugroup_name})が存在しない\n",
    "\n",
    "学習システムを構築していない場合(training_system = False)、あらかじめ用意してあるモデルと重みを作業領域にコピーします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lc_cell_meme": {
     "current": "672f6174-d0e3-11ec-b26a-0242ac110002-3-7c89-256b-e677",
     "next": "db53ae26-a9ff-11ec-b2f2-02420a010024-6-d415-e148-0bf3-8850-9b89-80af",
     "previous": "672f5f8a-d0e3-11ec-b26a-0242ac110002-3-a463-3dba-59f6"
    },
    "lc_wrapper": {}
   },
   "outputs": [],
   "source": [
    "# 学習済みモデル・重みファイル\n",
    "fe_save_dir = './data'            # フロントエンド重み保存フォルダ\n",
    "model_file = 'saved_model.tgz'    # ファイル名\n",
    "\n",
    "### 構築時パラメータの読み込み\n",
    "%run scripts/ts/group.py\n",
    "rs_gvars = load_group_vars(rs_ugroup_name)\n",
    "print(rs_gvars)\n",
    "if rs_gvars['training_system']:\n",
    "    ts_gvars = load_group_vars(rs_gvars['ts_ugroup_name'], \"../1.learning_system/\" + rs_gvars['ohpc_WORK_DIR'])\n",
    "    print(ts_gvars)\n",
    "else:\n",
    "    !cp -p ./original/model/{model_file} {fe_save_dir}/{model_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "db53ae26-a9ff-11ec-b2f2-02420a010024-6-d415-e148-0bf3-8850-9b89-80af",
     "next": "db53af16-a9ff-11ec-b2f2-02420a010024-6-7da1-5350-b462-2f2d-127f-9ee7",
     "previous": "672f6174-d0e3-11ec-b26a-0242ac110002-3-7c89-256b-e677"
    }
   },
   "source": [
    "### 内部パラメタの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lc_cell_meme": {
     "current": "db53af16-a9ff-11ec-b2f2-02420a010024-6-7da1-5350-b462-2f2d-127f-9ee7",
     "next": "db53b024-a9ff-11ec-b2f2-02420a010024-6-f721-e420-b99c-8ec9-2326-0866",
     "previous": "db53ae26-a9ff-11ec-b2f2-02420a010024-6-d415-e148-0bf3-8850-9b89-80af"
    },
    "lc_wrapper": {}
   },
   "outputs": [],
   "source": [
    "### 学習システム、認識システム共通 ###############################\n",
    "# 作業ディレクトリ（学習システム、認識システムとも同じパス）\n",
    "tf_work_dir = rs_gvars['tf_work_dir']\n",
    "\n",
    "\n",
    "### 認識システム ##############################################\n",
    "# コマンドラインオプション\n",
    "rs_user = rs_gvars['rs_user']\n",
    "rs_user_ssh_opts = f'-i {rs_gvars[\"rs_user_prvkey\"]}'\n",
    "rs_target = f'{rs_user}@{rs_gvars[\"rs_ipaddress\"]}'     # 認識システム構築時の ipaddress を使用。停止・再起動未対応\n",
    "\n",
    "\n",
    "### 学習システム ##############################################\n",
    "# 学習システムを構築していない場合は、認識システムを使用\n",
    "if rs_gvars['training_system']:\n",
    "    ts_user = ts_gvars['ohpc_user']\n",
    "    ts_user_ssh_opts = f'-i {ts_gvars[\"ohpc_user_prvkey\"]}'\n",
    "    ts_target = f'{ts_user}@{ts_gvars[\"master_ipaddress\"]}'\n",
    "else:\n",
    "    ts_user = rs_user\n",
    "    ts_user_ssh_opts = rs_user_ssh_opts\n",
    "    ts_target = rs_target\n",
    "\n",
    "\n",
    "### フロントエンド（本Jupyter Notebook）############\n",
    "# 認識スクリプトを格納しているディレクトリ\n",
    "scripts = './scripts/recognition'\n",
    "\n",
    "# フリーハンド入力した数字を格納するイメージファイル名（Jupyter上）\n",
    "img_file = f'{fe_save_dir}/base64_img.b64'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "db53b024-a9ff-11ec-b2f2-02420a010024-6-f721-e420-b99c-8ec9-2326-0866",
     "next": "d96180e8-cf39-11ec-b26a-0242ac110002-3-ab72-eb7b-46e9",
     "previous": "db53af16-a9ff-11ec-b2f2-02420a010024-6-7da1-5350-b462-2f2d-127f-9ee7"
    }
   },
   "source": [
    "### 学習結果を認識システムへ転送、展開"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "d96180e8-cf39-11ec-b26a-0242ac110002-3-ab72-eb7b-46e9",
     "next": "db53b114-a9ff-11ec-b2f2-02420a010024-6-3f5d-18f9-483f-aaf2-7a4a-ca50",
     "previous": "db53b024-a9ff-11ec-b2f2-02420a010024-6-f721-e420-b99c-8ec9-2326-0866"
    }
   },
   "source": [
    "学習システムで学習したモデルと学習結果を認識システムに転送し展開します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lc_cell_meme": {
     "current": "db53b114-a9ff-11ec-b2f2-02420a010024-6-3f5d-18f9-483f-aaf2-7a4a-ca50",
     "next": "f2d983a6-d1e4-11ec-b26a-0242ac110002-3-a14f-63a3-5eeb",
     "previous": "d96180e8-cf39-11ec-b26a-0242ac110002-3-ab72-eb7b-46e9"
    },
    "lc_wrapper": {}
   },
   "outputs": [],
   "source": [
    "# 学習結果を認識システムにアップロードし展開\n",
    "!ssh {rs_user_ssh_opts} {rs_target} rm -rf {tf_work_dir}/{model_file} {tf_work_dir}/saved_model\n",
    "!scp {rs_user_ssh_opts} -qp {fe_save_dir}/{model_file} {rs_target}:{tf_work_dir}\n",
    "!ssh {rs_user_ssh_opts} {rs_target} '(cd {tf_work_dir}; tar zxpf {model_file})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "f2d983a6-d1e4-11ec-b26a-0242ac110002-3-a14f-63a3-5eeb",
     "next": "1c4ba06c-d1e4-11ec-b26a-0242ac110002-3-bfd4-e587-90f8",
     "previous": "db53b114-a9ff-11ec-b2f2-02420a010024-6-3f5d-18f9-483f-aaf2-7a4a-ca50"
    }
   },
   "source": [
    "### フリーハンド認識の準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lc_cell_meme": {
     "current": "1c4ba06c-d1e4-11ec-b26a-0242ac110002-3-bfd4-e587-90f8",
     "next": "6f760d48-d7fe-11ec-b26a-0242ac110002-3-8088-20f3-f23e",
     "previous": "f2d983a6-d1e4-11ec-b26a-0242ac110002-3-a14f-63a3-5eeb"
    },
    "lc_wrapper": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.core.display import HTML\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def recognise(image):\n",
    "    # イメージをファイルに保存\n",
    "    with open(img_file, \"w\") as f1:\n",
    "        f1.write(image)\n",
    "    \n",
    "    # 確認のため MNIST のイメージサイズ(28x28)に変換して、拡大表示\n",
    "    img = Image.open(BytesIO(base64.b64decode(base64_img.split(\",\")[-1]))).resize((28,28))\n",
    "    plt.imshow(np.asarray(img))\n",
    "    plt.show()\n",
    "\n",
    "    # VCノードへイメージを転送し認識\n",
    "    !scp {rs_user_ssh_opts} -qp {img_file} {rs_target}:{tf_work_dir}\n",
    "    !ssh {rs_user_ssh_opts} {rs_target} docker exec -t -u {rs_user} -w /home/{rs_user}/{tf_work_dir} tensorflow-{rs_user} python3 mnist_predict.py\n",
    "\n",
    "# raise Exception(\"\\nStopped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "6f760d48-d7fe-11ec-b26a-0242ac110002-3-8088-20f3-f23e",
     "next": "6f7610f4-d7fe-11ec-b26a-0242ac110002-3-0cca-74b9-bdd7",
     "previous": "1c4ba06c-d1e4-11ec-b26a-0242ac110002-3-bfd4-e587-90f8"
    }
   },
   "source": [
    "### バッチジョブ操作関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lc_cell_meme": {
     "current": "6f7610f4-d7fe-11ec-b26a-0242ac110002-3-0cca-74b9-bdd7",
     "next": "db53b3a8-a9ff-11ec-b2f2-02420a010024-6-e892-de8d-ea86-db51-f747-22e8",
     "previous": "6f760d48-d7fe-11ec-b26a-0242ac110002-3-8088-20f3-f23e"
    },
    "lc_wrapper": {}
   },
   "outputs": [],
   "source": [
    "# バッチジョブ投入関数定義(slurm 用)\n",
    "def qsub(job, work_dir=\".\"):\n",
    "    bs_state = !ssh {ts_user_ssh_opts} {ts_target} bash -l -c \"'cd {work_dir} && sbatch {job}'\"\n",
    "    bs_state = bs_state[len(bs_state)-1]\n",
    "    print(bs_state)\n",
    "\n",
    "    if bs_state.split()[0] == 'Submitted':\n",
    "        return bs_state.split()[3]\n",
    "    else:\n",
    "        raise RuntimeError('ERROR: job submission error')\n",
    "\n",
    "        \n",
    "def qstat(bs_jobid):\n",
    "    print('job ' + bs_jobid + ':', end = ' ')\n",
    "    while True:\n",
    "        bs_state = !ssh {ts_user_ssh_opts} {ts_target} bash -l -c 'squeue --noheader --jobs={bs_jobid}'\n",
    "        bs_state = bs_state[len(bs_state)-1]\n",
    "        if bs_state == '' or bs_state.split()[0] == 'JOBID':\n",
    "            break\n",
    "        elif 'error' in bs_state:\n",
    "            raise RuntimeError(bs_state)\n",
    "        else:\n",
    "            print(\"\", end = '.')\n",
    "            !sleep 5\n",
    "    print(' finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "db53b3a8-a9ff-11ec-b2f2-02420a010024-6-e892-de8d-ea86-db51-f747-22e8",
     "next": "63d21ae2-d1e4-11ec-b26a-0242ac110002-3-05d9-151e-43cb",
     "previous": "6f7610f4-d7fe-11ec-b26a-0242ac110002-3-0cca-74b9-bdd7"
    }
   },
   "source": [
    "## フリーハンド数字入力と認識\n",
    "数字（一桁の'0-9'）をフリーハンドで入力します。マウスをクリックしながら描画してください。描画が終わったら、`Save`ボタンをクリックし、２つ目のセルを実行してください。入力したイメージをVCノードのTensorFlow環境に転送し認識します。\n",
    "\n",
    "１つ目のセル（入力環境）は２つ目のセルを実行した後も実行が継続されています。`Clear`で描画エリアをクリア後、再度入力し`Save`をクリックしてください。\n",
    "\n",
    "２つ目のセルは凍結を解除し再実行することで再入力した数字を認識します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lc_cell_meme": {
     "current": "63d21ae2-d1e4-11ec-b26a-0242ac110002-3-05d9-151e-43cb",
     "next": "ab5f13a6-d1e4-11ec-b26a-0242ac110002-3-eb08-1049-4ae0",
     "previous": "db53b3a8-a9ff-11ec-b2f2-02420a010024-6-e892-de8d-ea86-db51-f747-22e8"
    },
    "lc_wrapper": {}
   },
   "outputs": [],
   "source": [
    "# フリーハンド数字入力、base64形式イメージ化\n",
    "%run scripts/frontend/fhinput.py\n",
    "HTML(fhinput())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lc_cell_meme": {
     "current": "ab5f13a6-d1e4-11ec-b26a-0242ac110002-3-eb08-1049-4ae0",
     "next": "db53b678-a9ff-11ec-b2f2-02420a010024-6-d3db-072c-db44-6172-b3cd-ecf9",
     "previous": "63d21ae2-d1e4-11ec-b26a-0242ac110002-3-05d9-151e-43cb"
    },
    "lc_wrapper": {}
   },
   "outputs": [],
   "source": [
    "recognise(base64_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "db53b678-a9ff-11ec-b2f2-02420a010024-6-d3db-072c-db44-6172-b3cd-ecf9",
     "next": "db53b77c-a9ff-11ec-b2f2-02420a010024-6-7c12-64ba-0c01-c5c8-fd62-f0af",
     "previous": "ab5f13a6-d1e4-11ec-b26a-0242ac110002-3-eb08-1049-4ae0"
    }
   },
   "source": [
    "## 誤答が多い？　GPU 資源は利用料が高い？　いろいろ試してみましょう。\n",
    "学習時のテストでは97%以上の認識精度が出ているのに、誤認識が多いと思います。改善のためいろいろ試してみます。そして、コスト低減を考慮し認識システムでの学習を試します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "db53b77c-a9ff-11ec-b2f2-02420a010024-6-7c12-64ba-0c01-c5c8-fd62-f0af",
     "next": "db53b858-a9ff-11ec-b2f2-02420a010024-6-7597-8fac-4e21-7023-a337-5433",
     "previous": "db53b678-a9ff-11ec-b2f2-02420a010024-6-d3db-072c-db44-6172-b3cd-ecf9"
    }
   },
   "source": [
    "### 一般的な機械学習ベースの認識システムの誤認識対応"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "db53b858-a9ff-11ec-b2f2-02420a010024-6-7597-8fac-4e21-7023-a337-5433",
     "next": "db53b952-a9ff-11ec-b2f2-02420a010024-6-70e0-ac01-a400-fc46-c92e-c4c2",
     "previous": "db53b77c-a9ff-11ec-b2f2-02420a010024-6-7c12-64ba-0c01-c5c8-fd62-f0af"
    }
   },
   "source": [
    "アプリ運用中に誤答が多くなると、誤答データ（イメージ）と正解ラベルを学習システムに戻して追加学習し、誤答に対応するのが一般的です。\n",
    "しかし、その前にこの認識システムには基本的な問題があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "db53b952-a9ff-11ec-b2f2-02420a010024-6-70e0-ac01-a400-fc46-c92e-c4c2",
     "next": "db53ba38-a9ff-11ec-b2f2-02420a010024-6-970c-1308-ff1e-2374-37b4-0803",
     "previous": "db53b858-a9ff-11ec-b2f2-02420a010024-6-7597-8fac-4e21-7023-a337-5433"
    }
   },
   "source": [
    "### ニューラルネットワークモデルは適切か？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "db53ba38-a9ff-11ec-b2f2-02420a010024-6-970c-1308-ff1e-2374-37b4-0803",
     "next": "43d9061c-d7ff-11ec-b26a-0242ac110002-3-6458-057c-ec95",
     "previous": "db53b952-a9ff-11ec-b2f2-02420a010024-6-70e0-ac01-a400-fc46-c92e-c4c2"
    }
   },
   "source": [
    "このNotebookのMNISTのニューラルネットワークのモデルは、TensorFlowホームページの「初心者のための TensorFlow 2.0 入門」を基にしており、フラットな４層ニューラルネットワークです（scripts/tensorflow/mnist_train.py）。\n",
    "\n",
    "```\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "```\n",
    "\n",
    "一般に、フラットなモデル（ある層の全てのユニットが前の層の全てのユニットに接続する）で高い認識精度を求めるするのは非常に難しいと考えられます。学習時のテストで97%以上の高い精度を示したのは、テストデータの中に学習データと同じ筆者のデータが含まれているためと思われます。もう一つ重要な理由がありますが、それは後ほど。\n",
    "\n",
    "画像認識では、畳み込みニューラルネットワーク（CNN）がよく使われます。フラットなモデルとの違いは、\n",
    "\n",
    "* フラット: 各層でイメージまたは前層の出力全体を認識します\n",
    "* CNN: 畳み込み層はイメージまたは前層の出力の小領域の部分特徴を認識します。次の畳み込み層では前層の部分特徴の組み合わせをさらに部分特徴として認識します（結果として、前層より入力層の大きな部分を見ることになります）。これを積み重ねることにより、最終的に全体を認識します\n",
    "\n",
    "Tensorflow の CNN とは異なりますが、畳み込みによる文字認識の仕組みがわかりやすいので、ネオコグニトロンの認識の仕組みを示します。\n",
    "\n",
    "![構成](images/231.neocognitron.png)\n",
    "\n",
    "部分的なパターンの認識結果を次の層で組み合わせます。このとき前の層のパターンに部分的な変形や位置がずれがあっても、層を重ねるにつれ徐々に影響が薄れ、最終的には影響を受けにくくなります。フラットなモデルの場合、前の層のパターン全体を見るので、変形や位置ずれの影響が最終層まで残りやすくなっています。なお、サル（おそらく人間も）の一次視覚野には、角度別の微小な線分に反応する細胞が存在することが生理学的に確認されています。\n",
    "\n",
    "では、CNNで学習して認識精度を見てみましょう。モデルは以下の通りです（scripts/tensorflow/mnist_training2.py）。\n",
    "\n",
    "```\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (5,5), activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (5,5), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "```\n",
    "\n",
    "CNN で学習するためのジョブを投入します。学習システムを構築していない場合は実行せず、あらかじめ用意している CNN での学習結果を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lc_cell_meme": {
     "current": "43d9061c-d7ff-11ec-b26a-0242ac110002-3-6458-057c-ec95",
     "next": "db53bf6a-a9ff-11ec-b2f2-02420a010024-6-5667-da79-b2c1-e028-f530-34aa",
     "previous": "db53ba38-a9ff-11ec-b2f2-02420a010024-6-970c-1308-ff1e-2374-37b4-0803"
    },
    "lc_wrapper": {}
   },
   "outputs": [],
   "source": [
    "if rs_gvars['training_system']:\n",
    "    # 以前の学習ジョブ結果の削除\n",
    "    !ssh {ts_user_ssh_opts} {ts_target} bash -l -c \\\n",
    "        \"'cd {tf_work_dir} && rm -rf  tensorflow-mnist*.out saved_model*'\"\n",
    "\n",
    "    # 学習ジョブの投入と実行終了待ち\n",
    "    jobid = qsub('tensorflow_mnist_docker_ho2.job', tf_work_dir)\n",
    "    qstat(jobid)\n",
    "    \n",
    "    # 学習結果の表示。学習時の認識精度はフラットなニューラルネットより向上しているのがわかります（97.5%程度→99%程度)\n",
    "    !ssh {ts_user_ssh_opts} {ts_target} bash -l -c \\\n",
    "        \"'cd {tf_work_dir} && tail tensorflow-mnist*.out'\"\n",
    "    \n",
    "else:\n",
    "    !cp -p ./original/model/saved_model2.tgz {fe_save_dir}/{model_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "db53bf6a-a9ff-11ec-b2f2-02420a010024-6-5667-da79-b2c1-e028-f530-34aa",
     "next": "db53c064-a9ff-11ec-b2f2-02420a010024-6-b1ba-3826-7016-e651-5605-a70b",
     "previous": "43d9061c-d7ff-11ec-b26a-0242ac110002-3-6458-057c-ec95"
    }
   },
   "source": [
    "学習結果（学習モデルと重み）を、認識システムに展開します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lc_cell_meme": {
     "current": "db53c064-a9ff-11ec-b2f2-02420a010024-6-b1ba-3826-7016-e651-5605-a70b",
     "next": "db53c12c-a9ff-11ec-b2f2-02420a010024-6-654a-622e-eccf-d2b0-bd67-7c36",
     "previous": "db53bf6a-a9ff-11ec-b2f2-02420a010024-6-5667-da79-b2c1-e028-f530-34aa"
    },
    "lc_wrapper": {}
   },
   "outputs": [],
   "source": [
    "# 学習システムでの学習結果をフロントエンドにダウンロード\n",
    "!scp {ts_user_ssh_opts} -p {ts_target}:{tf_work_dir}/{model_file} {fe_save_dir}\n",
    "\n",
    "# 学習結果を認識システムにアップロードし展開\n",
    "!ssh {rs_user_ssh_opts} {rs_target} rm -rf {tf_work_dir}/{model_file} {tf_work_dir}/saved_model\n",
    "!scp {rs_user_ssh_opts} -qp {fe_save_dir}/{model_file} {rs_target}:{tf_work_dir}\n",
    "!ssh {rs_user_ssh_opts} {rs_target} '(cd {tf_work_dir}; tar zxpf {model_file})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "db53c12c-a9ff-11ec-b2f2-02420a010024-6-654a-622e-eccf-d2b0-bd67-7c36",
     "next": "db53c1fe-a9ff-11ec-b2f2-02420a010024-6-695e-2ada-cc53-49c2-8d54-0ff7",
     "previous": "db53c064-a9ff-11ec-b2f2-02420a010024-6-b1ba-3826-7016-e651-5605-a70b"
    }
   },
   "source": [
    "上のフリーハンド入力のセルに戻って、試してみてください。\n",
    "多少改善されているはずです。確認したら戻って次の節を試してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "db53c1fe-a9ff-11ec-b2f2-02420a010024-6-695e-2ada-cc53-49c2-8d54-0ff7",
     "next": "db53c596-a9ff-11ec-b2f2-02420a010024-6-c788-5dbd-a263-5093-c773-03c7",
     "previous": "db53c12c-a9ff-11ec-b2f2-02420a010024-6-654a-622e-eccf-d2b0-bd67-7c36"
    }
   },
   "source": [
    "### ニューラルネットワークに与えるデータは適切か？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "db53c596-a9ff-11ec-b2f2-02420a010024-6-c788-5dbd-a263-5093-c773-03c7",
     "next": "a67f6324-cf35-11ec-b26a-0242ac110002-3-03ba-985b-4a0e",
     "previous": "db53c1fe-a9ff-11ec-b2f2-02420a010024-6-695e-2ada-cc53-49c2-8d54-0ff7"
    }
   },
   "source": [
    "人間でも真正面の文字を認識するときと、視線の中心から少し外れた文字を認識するときとでは、後者の方が誤認識が多くなると思います。これは人工的なニューラルネットでも同じです。本当は、上記のようなニューラルネットのモデルの違いより、画像が認識領域の中心にあるか否かが大きく影響します。そこで、入力システムに描いた画像を中心に移動する機能を追加しました。試してみてください。\n",
    "\n",
    "`Save`ボタンで従来通り保存して認識してみてください。次に画像を変えずに`Centralize and save`で画像を中心に配置して保存して認識してみてください。上の入力システムと同様に、２つ目のセル（認識）を実行した後も機能しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lc_cell_meme": {
     "current": "a67f6324-cf35-11ec-b26a-0242ac110002-3-03ba-985b-4a0e",
     "next": "81f1cff8-d1e5-11ec-b26a-0242ac110002-3-f796-d4e1-4dc1",
     "previous": "db53c596-a9ff-11ec-b2f2-02420a010024-6-c788-5dbd-a263-5093-c773-03c7"
    },
    "lc_wrapper": {}
   },
   "outputs": [],
   "source": [
    "# フリーハンド数字入力、base64形式イメージ化\n",
    "%run scripts/frontend/fhinput.py\n",
    "HTML(fhinput2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lc_cell_meme": {
     "current": "81f1cff8-d1e5-11ec-b26a-0242ac110002-3-f796-d4e1-4dc1",
     "next": "db53c820-a9ff-11ec-b2f2-02420a010024-6-cf46-0294-6b9f-2e32-41e2-6143",
     "previous": "a67f6324-cf35-11ec-b26a-0242ac110002-3-03ba-985b-4a0e"
    },
    "lc_wrapper": {}
   },
   "outputs": [],
   "source": [
    "recognise(base64_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "db53c820-a9ff-11ec-b2f2-02420a010024-6-cf46-0294-6b9f-2e32-41e2-6143",
     "next": "db53c910-a9ff-11ec-b2f2-02420a010024-6-b413-b55b-cc4c-a4b2-532a-c1ac",
     "previous": "81f1cff8-d1e5-11ec-b26a-0242ac110002-3-f796-d4e1-4dc1"
    }
   },
   "source": [
    "かなり、認識精度が向上したと思います。本Notebookでの認識精度の向上はここまでとします。\n",
    "\n",
    "なお、今回使用したCNNは４層です（CNNは最初の2層のみ）。ニューラルネットは層が多いほど複雑な動作ができます。例えば、AND や OR は中間層のない１層で実現できますが、さらに複雑な動作である XOR は少なくとも１つの中間層が必要です（２層モデル）。このように、多層になるほど複雑な動作ができると考えられるので、フラットなニューラルネットでも層数を増やせば精度が上がるかもしれません。ちなみに、認識精度の高いニューラルネットの多くはCNNを使っていますが１００層を超えます。\n",
    "\n",
    "興味ある方は ./scripts/recognition の mnist_train.py や mnist_train_cnn.py を編集して試してみてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "db53c910-a9ff-11ec-b2f2-02420a010024-6-b413-b55b-cc4c-a4b2-532a-c1ac",
     "next": "db53c9e2-a9ff-11ec-b2f2-02420a010024-6-0209-cc7d-feb9-4ffb-38e4-1a49",
     "previous": "db53c820-a9ff-11ec-b2f2-02420a010024-6-cf46-0294-6b9f-2e32-41e2-6143"
    }
   },
   "source": [
    "### 利用している資源のspecは適切か？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "db53c9e2-a9ff-11ec-b2f2-02420a010024-6-0209-cc7d-feb9-4ffb-38e4-1a49",
     "next": "db53cad2-a9ff-11ec-b2f2-02420a010024-6-6587-40f0-e341-daa4-3cf8-8bde",
     "previous": "db53c910-a9ff-11ec-b2f2-02420a010024-6-b413-b55b-cc4c-a4b2-532a-c1ac"
    }
   },
   "source": [
    "今回は[OpenHPC-v2](https://github.com/nii-gakunin-cloud/ocs-templates/tree/master/OpenHPC-v2)と同様に GPU 資源を使いましたが、MNIST 程度の小規模データ、小規模ニューラルネットワークモデルでは、CPU だけの環境でも学習するのにさほど時間はかかりません。認識システムとして構築した CPU のみの環境で学習させてみます。本節の学習結果による認識は、前節の入力システムで確認できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "db53cad2-a9ff-11ec-b2f2-02420a010024-6-6587-40f0-e341-daa4-3cf8-8bde",
     "next": "db53cbae-a9ff-11ec-b2f2-02420a010024-6-632f-276f-de08-62ab-6006-8199",
     "previous": "db53c9e2-a9ff-11ec-b2f2-02420a010024-6-0209-cc7d-feb9-4ffb-38e4-1a49"
    }
   },
   "source": [
    "#### フラットなニューラルネットワークを CPU のみの環境で学習\n",
    "学習は１分以内に終了するはずです。なお、認識システムの実行環境は、ジョブスケジューラではなくインタラクティブ環境のためセルの実行の終了が学習の終了です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lc_cell_meme": {
     "current": "db53cbae-a9ff-11ec-b2f2-02420a010024-6-632f-276f-de08-62ab-6006-8199",
     "next": "db53cc80-a9ff-11ec-b2f2-02420a010024-6-76b5-087a-7773-abcd-a427-a7c6",
     "previous": "db53cad2-a9ff-11ec-b2f2-02420a010024-6-6587-40f0-e341-daa4-3cf8-8bde"
    },
    "lc_wrapper": {}
   },
   "outputs": [],
   "source": [
    "!ssh {rs_user_ssh_opts} {rs_target} rm -rf {tf_work_dir}/saved_model\n",
    "!ssh {rs_user_ssh_opts} {rs_target} docker exec -t -u {rs_user} -w /home/{rs_user}/{tf_work_dir} tensorflow-{rs_user} python3 download_mnist.py\n",
    "!ssh {rs_user_ssh_opts} {rs_target} docker exec -t -u {rs_user} -w /home/{rs_user}/{tf_work_dir} tensorflow-{rs_user} python3 mnist_train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lc_cell_meme": {
     "current": "db53cc80-a9ff-11ec-b2f2-02420a010024-6-76b5-087a-7773-abcd-a427-a7c6",
     "next": "db53cd5c-a9ff-11ec-b2f2-02420a010024-6-63f5-027f-e867-006e-af7e-d9bd",
     "previous": "db53cbae-a9ff-11ec-b2f2-02420a010024-6-632f-276f-de08-62ab-6006-8199"
    }
   },
   "source": [
    "#### CNN を CPU のみの環境で学習\n",
    "学習は８分程度で終了するはずです。時間に余裕がある方は試してみてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lc_cell_meme": {
     "current": "db53cd5c-a9ff-11ec-b2f2-02420a010024-6-63f5-027f-e867-006e-af7e-d9bd",
     "next": "b8b7fbec-c957-11ed-892b-0242ac110003-2-ccfa-450c",
     "previous": "db53cc80-a9ff-11ec-b2f2-02420a010024-6-76b5-087a-7773-abcd-a427-a7c6"
    },
    "lc_wrapper": {}
   },
   "outputs": [],
   "source": [
    "!ssh {rs_user_ssh_opts} {rs_target} rm -rf {tf_work_dir}/saved_model\n",
    "!ssh {rs_user_ssh_opts} {rs_target} docker exec -t -u {rs_user} -w /home/{rs_user}/{tf_work_dir} tensorflow-{rs_user} python3 download_mnist.py\n",
    "!ssh {rs_user_ssh_opts} {rs_target} docker exec -t -u {rs_user} -w /home/{rs_user}/{tf_work_dir} tensorflow-{rs_user} python3 mnist_train_cnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lc_cell_meme": {
     "current": "b8b7fbec-c957-11ed-892b-0242ac110003-2-ccfa-450c",
     "next": null,
     "previous": "db53cd5c-a9ff-11ec-b2f2-02420a010024-6-63f5-027f-e867-006e-af7e-d9bd"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "826px",
    "left": "0px",
    "right": "1202px",
    "top": "111px",
    "width": "310px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
